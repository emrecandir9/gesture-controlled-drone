{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import argparse\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from utils.helper_func import HelperFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_type = {1: 'hand', \n",
    "                2: 'body'}\n",
    "\n",
    "gestures = {1:'up', \n",
    "            2:'down', \n",
    "            3:'right', \n",
    "            4:'left', \n",
    "            5:'further', \n",
    "            6: 'closer', \n",
    "            7: 'land', \n",
    "            8: 'take_off', \n",
    "            9: 'photo', \n",
    "            10: 'video', \n",
    "            11: 'video_pause', \n",
    "            12: 'emergency', \n",
    "            13: 'follow', \n",
    "            14: 'palm',\n",
    "            15: 'no_class'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Gesture Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total frames in videos\n",
    "image_num = 0\n",
    "# Processed image number\n",
    "pro_image_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = HelperFunc()\n",
    "working_dir = os.path.dirname(os.getcwd()) \n",
    "videos_path = os.path.join(working_dir, 'videos' )\n",
    "photos_path = os.path.join(working_dir, 'photos')\n",
    "\n",
    "for gesture_type in os.listdir(videos_path):\n",
    "    for gesture_class in os.listdir(os.path.join(videos_path,gesture_type)):\n",
    "        gesture_path = os.path.join(videos_path,gesture_type, gesture_class)\n",
    "\n",
    "        for video in os.listdir(gesture_path):\n",
    "            if not gesture_type == 'body':\n",
    "\n",
    "                # Path to the specific video\n",
    "                video_path = os.path.join(gesture_path, video)\n",
    "\n",
    "                # Capturing Video\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                \n",
    "                mp_drawing = mp.solutions.drawing_utils\n",
    "                mp_hands = mp.solutions.hands\n",
    "\n",
    "                # Get the frame rate of the video\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                # Calculate the frame skip value\n",
    "                frame_skip = int(fps / 1)\n",
    "                # Total frames\n",
    "                frame_count = 0\n",
    "                \n",
    "                # Wheter using pose library\n",
    "                use_pose = False\n",
    "\n",
    "                # Set True to save original and annotated frames\n",
    "                save_frames = True\n",
    "\n",
    "                # Create a directory to store the output images\n",
    "                output_dir = os.path.join(photos_path,gesture_type, gesture_class)\n",
    "                \n",
    "                with mp_hands.Hands(\n",
    "                    max_num_hands=1,\n",
    "                    min_detection_confidence=min_detection_confidence,\n",
    "                    min_tracking_confidence=min_tracking_confidence) as hands:\n",
    "\n",
    "                    while cap.isOpened():\n",
    "                        # Capture the frame\n",
    "                        ret, frame = cap.read()\n",
    "\n",
    "                        if not ret:\n",
    "                            print(\"Ignoring empty camera frame.\")\n",
    "                            break \n",
    "\n",
    "                        # Create copy of frame\n",
    "                        copy_frame = copy.deepcopy(frame)\n",
    "\n",
    "                        # Convert the frame to RGB format\n",
    "                        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        # To improve performance, optionally mark the image as not writeable to\n",
    "                        frame.flags.writeable = False\n",
    "\n",
    "                        # Process the frame with the MediaPipe Hands class\n",
    "                        results = hands.process(rgb_frame)\n",
    "\n",
    "                        if frame_count % frame_skip == 0:\n",
    "                            # Total frames in videos\n",
    "                            image_num +=1\n",
    "                            \n",
    "                            # Check if any hands were detected\n",
    "                            if results.multi_hand_landmarks:\n",
    "                                for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "                                    # Check if the detected hand is Left\n",
    "                                    hand_label = results.multi_handedness[0].classification[0].label\n",
    "                                    if hand_label == 'Left':\n",
    "\n",
    "                                        # Processed image number\n",
    "                                        pro_image_num +=1\n",
    "\n",
    "                                        # Landmark list calculation\n",
    "                                        landmark_list = functions.calc_landmark_list(rgb_frame, hand_landmarks,use_pose)\n",
    "                                        # Preprocessing landmark list\n",
    "                                        pre_processed_landmark_list = functions.pre_process_landmark(landmark_list)\n",
    "                                        # writing preprocessed list to the csv file\n",
    "                                        functions.write_csv(functions.get_key_from_value(gestures,gesture_class), pre_processed_landmark_list,use_pose)\n",
    "                                        \n",
    "                                        \"\"\"# Bounding box calculation\n",
    "                                        brect = functions.calc_bounding_rect(rgb_frame, hand_landmarks)\n",
    "                                        # Drawing the bounding box on the frame\n",
    "                                        frame = functions.rect_corners(frame, brect)\n",
    "\n",
    "                                        # Drawing the hand landmarks on the frame\n",
    "                                        mp_drawing.draw_landmarks(\n",
    "                                            frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                            mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=3),\n",
    "                                            mp_drawing.DrawingSpec(color=(121,44,250), thickness=2))\"\"\"\n",
    "                                        \n",
    "                                        if save_frames: \n",
    "                                            #create unique id for every frame\n",
    "                                            unique_id = uuid.uuid4()\n",
    "                                            unique_id = str(unique_id)\n",
    "                                            # Construct output file paths for original and anonotated images\n",
    "                                            #output_ann = f\"{output_dir}/{unique_id}_ann.jpg\"\n",
    "                                            output_orj = f\"{output_dir}/{unique_id}_org.jpg\"\n",
    "                                            # Save the frame as a JPEG file\n",
    "                                            cv2.imwrite(output_orj, copy_frame)\n",
    "                                            #cv2.imwrite(output_ann, frame)\n",
    "\n",
    "                        frame_count += 1\n",
    "                        # Display the frame\n",
    "                        cv2.imshow('Hand Detection', frame)\n",
    "\n",
    "                        # Break the loop if 'q' key is pressed\n",
    "                        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                            break\n",
    "                    \n",
    "                        print('Video {} processed successfully'.format(video_path))\n",
    "\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames in Videos= 789\n",
      "Total Processed Frames = 786\n",
      "Number of Useless Frames = 3\n"
     ]
    }
   ],
   "source": [
    "print('Total Frames in Videos= {}\\nTotal Processed Frames = {}\\nNumber of Useless Frames = {}'.format(image_num,pro_image_num,(image_num-pro_image_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body Gesture Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total frames in videos\n",
    "image_num_pose = 0\n",
    "# Processed image number\n",
    "pro_image_num_pose = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = HelperFunc()\n",
    "working_dir = os.path.dirname(os.getcwd()) \n",
    "videos_path = os.path.join(working_dir, 'videos' )\n",
    "photos_path = os.path.join(working_dir, 'photos')\n",
    "\n",
    "for gesture_type in os.listdir(videos_path):\n",
    "    for gesture_class in os.listdir(os.path.join(videos_path,gesture_type)):\n",
    "        gesture_path = os.path.join(videos_path,gesture_type, gesture_class)\n",
    "\n",
    "        for video in os.listdir(gesture_path):\n",
    "            if not gesture_type == 'hand':\n",
    "\n",
    "\n",
    "                # Path to the specific video\n",
    "                video_path = os.path.join(gesture_path, video)\n",
    "\n",
    "                # Capturing Video\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "                mp_drawing = mp.solutions.drawing_utils\n",
    "                mp_pose = mp.solutions.pose\n",
    "                                \n",
    "                # Get the frame rate of the video\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                # Calculate the frame skip value\n",
    "                frame_skip = int(fps / 1)\n",
    "                # Total frames\n",
    "                frame_count = 0\n",
    "\n",
    "                # Set True to save original and annotated frames\n",
    "                save_frames = True\n",
    "\n",
    "                # Create a directory to store the output images\n",
    "                output_dir = os.path.join(photos_path,gesture_type, gesture_class)\n",
    "\n",
    "                # Wheter to use bounding box\n",
    "                use_brect = True\n",
    "                \n",
    "                # Wheter using pose library\n",
    "                use_pose = True\n",
    "\n",
    "                with mp_pose.Pose(\n",
    "                    min_detection_confidence=min_detection_confidence,\n",
    "                    min_tracking_confidence=min_tracking_confidence) as pose:\n",
    "                    \n",
    "                    while cap.isOpened():\n",
    "                        # Capture the frame\n",
    "                        ret, frame = cap.read()\n",
    "\n",
    "                        if not ret:\n",
    "                            print(\"Ignoring empty camera frame.\")\n",
    "                            break\n",
    "                        \n",
    "                        # Create copy of frame\n",
    "                        copy_frame = copy.deepcopy(frame)\n",
    "\n",
    "                        # Convert the frame to RGB format\n",
    "                        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                        # To improve performance, optionally mark the image as not writeable to\n",
    "                        frame.flags.writeable = False\n",
    "\n",
    "                        # Process the frame with the MediaPipe Pose class\n",
    "                        results = pose.process(rgb_frame)\n",
    "                        \n",
    "                        if frame_count % frame_skip == 0:\n",
    "                            # Total frames in videos\n",
    "                            image_num_pose +=1\n",
    "\n",
    "                            if results.pose_landmarks:\n",
    "                                # Processed image number\n",
    "                                pro_image_num_pose +=1\n",
    "\n",
    "                                # Landmark list calculation\n",
    "                                landmark_list = functions.calc_landmark_list(rgb_frame, results.pose_landmarks,use_pose)\n",
    "                                # Preprocessing landmark list\n",
    "                                pre_processed_landmark_list = functions.pre_process_landmark(landmark_list)\n",
    "                                # writing preprocessed list to the csv file\n",
    "                                functions.write_csv(functions.get_key_from_value(gestures,gesture_class), pre_processed_landmark_list,use_pose)\n",
    "\n",
    "\n",
    "                                \"\"\"# Bounding box calculation\n",
    "                                brect = functions.calc_bounding_rect(rgb_frame, results.pose_landmarks)\n",
    "                                # Drawing the bounding box on the frame\n",
    "                                frame = functions.rect_corners(frame, brect)\n",
    "\n",
    "                                # Draw the pose annotation on the image.\n",
    "                                frame.flags.writeable = True\n",
    "\n",
    "                                mp_drawing.draw_landmarks(\n",
    "                                    frame,\n",
    "                                    results.pose_landmarks,\n",
    "                                    mp_pose.POSE_CONNECTIONS,\n",
    "                                    connection_drawing_spec = mp_drawing.DrawingSpec(color=(121,44,250), thickness=2),\n",
    "                                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(121,22,76), thickness=2,circle_radius=2))\n",
    "                                \"\"\"\n",
    "\n",
    "                                if save_frames: \n",
    "                                    #create unique id for every frame\n",
    "                                    unique_id = uuid.uuid4()\n",
    "                                    unique_id = str(unique_id)\n",
    "                                    # Construct output file paths for original and anonotated images\n",
    "                                    #output_ann = f\"{output_dir}/{unique_id}_ann.jpg\"\n",
    "                                    output_orj = f\"{output_dir}/{unique_id}_org.jpg\"\n",
    "                                    # Save the frame as a JPEG file\n",
    "                                    cv2.imwrite(output_orj, copy_frame)\n",
    "                                    #cv2.imwrite(output_ann, frame)\n",
    "\n",
    "                        frame_count += 1\n",
    "                        # Display the frame\n",
    "                        cv2.imshow('Pose Detection', frame)\n",
    "\n",
    "                        # Break the loop if 'q' key is pressed\n",
    "                        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                            break\n",
    "\n",
    "                    print('Video {} processed successfully'.format(video_path))\n",
    "\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames in Videos = 1849\n",
      "Total Processed Frames = 1844\n",
      "Number of Useless Frames = 5\n"
     ]
    }
   ],
   "source": [
    "print('Total Frames in Videos = {}\\nTotal Processed Frames = {}\\nNumber of Useless Frames = {}'.format(image_num_pose,pro_image_num_pose,(image_num_pose-pro_image_num_pose)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
